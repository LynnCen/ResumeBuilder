# å·¥ä½œæµç¼–æ’æ·±å…¥åŸç†

> **LangGraph ä¸çŠ¶æ€ç®¡ç†çš„æœ¬è´¨**

---

## ä¸€ã€ä¸ºä»€ä¹ˆéœ€è¦å·¥ä½œæµç¼–æ’ï¼Ÿ

### 1.1 ä»ç®€å•åˆ°å¤æ‚

**ç®€å•åœºæ™¯**ï¼šå•æ¬¡å·¥å…·è°ƒç”¨

```
ç”¨æˆ·ï¼šåŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ
  â†“
LLMï¼šè°ƒç”¨ get_weather("åŒ—äº¬")
  â†“
å·¥å…·ï¼šè¿”å›å¤©æ°”æ•°æ®
  â†“
LLMï¼šæ•´åˆç»“æœå¹¶å›å¤
```

è¿™å¯ä»¥ç”¨ç®€å•çš„ä»£ç å®ç°ï¼š

```python
async def simple_agent(user_input):
    # 1. è°ƒç”¨ LLM
    response = await llm.complete(user_input)
    
    # 2. è§£æå·¥å…·è°ƒç”¨
    tool_call = parse_tool_call(response)
    
    # 3. æ‰§è¡Œå·¥å…·
    tool_result = await execute_tool(tool_call)
    
    # 4. è®© LLM æ•´åˆç»“æœ
    final_response = await llm.complete(
        messages=[
            user_input,
            response,
            tool_result
        ]
    )
    
    return final_response
```

**å¤æ‚åœºæ™¯**ï¼šå¤šè½®å¯¹è¯ + å¤šæ¬¡å·¥å…·è°ƒç”¨ + ä¸­æ–­æ¢å¤

```
ç”¨æˆ·ï¼šå¸®æˆ‘è®¾è®¡ä¸€å¥—å“ç‰Œè§†è§‰
  â†“
LLMï¼šæˆ‘éœ€è¦å…ˆäº†è§£ä½ çš„å“ç‰Œå®šä½...
ç”¨æˆ·ï¼šæˆ‘æ˜¯ä¸€ä¸ªç‰™è†å“ç‰Œï¼Œä¸»æ‰“å¥åº·
  â†“
LLMï¼šè°ƒç”¨ generate_logo("ç‰™è†å“ç‰Œlogo")
  â†“
[ç¨¿è±†ä¸è¶³ï¼Œä¸­æ–­]
  â†“
[ç”¨æˆ·å……å€¼]
  â†“
ç”¨æˆ·ï¼šç»§ç»­
  â†“
[ä»ä¸­æ–­ç‚¹æ¢å¤]
  â†“
å·¥å…·ï¼šè¿”å› logo å›¾ç‰‡
  â†“
LLMï¼šè°ƒç”¨ generate_color_scheme("ç‰™è†å“ç‰Œé…è‰²")
  â†“
å·¥å…·ï¼šè¿”å›é…è‰²æ–¹æ¡ˆ
  â†“
LLMï¼šè°ƒç”¨ generate_poster("å“ç‰Œæµ·æŠ¥", logo, colors)
  â†“
å·¥å…·ï¼šè¿”å›æµ·æŠ¥
  â†“
LLMï¼šæ•´åˆæ‰€æœ‰ç»“æœå¹¶å±•ç¤º
```

**æŒ‘æˆ˜**ï¼š
1. **çŠ¶æ€ç®¡ç†**ï¼šå¦‚ä½•è®°å½•å½“å‰æ‰§è¡Œåˆ°å“ªä¸€æ­¥ï¼Ÿ
2. **ä¸­æ–­æ¢å¤**ï¼šå¦‚ä½•ä»ä¸­æ–­ç‚¹ç»§ç»­ï¼Ÿ
3. **é”™è¯¯å¤„ç†**ï¼šå¦‚ä½•å¤„ç†å·¥å…·è°ƒç”¨å¤±è´¥ï¼Ÿ
4. **å¾ªç¯æ§åˆ¶**ï¼šå¦‚ä½•é˜²æ­¢æ— é™å¾ªç¯ï¼Ÿ

### 1.2 LangGraph çš„ä»·å€¼

> ğŸ’¡ **æ ¸å¿ƒæ´å¯Ÿ**  
> LangGraph çš„æœ¬è´¨æ˜¯ï¼š**ä¸€ä¸ªæœ‰çŠ¶æ€çš„ã€å¯ä¸­æ–­æ¢å¤çš„ã€åŸºäºå›¾çš„å·¥ä½œæµç¼–æ’å¼•æ“**ã€‚

**ç±»æ¯”**ï¼š
- **ç®€å• Agent**ï¼šåƒä¸€ä¸ªå‡½æ•°è°ƒç”¨
- **LangGraph**ï¼šåƒä¸€ä¸ªçŠ¶æ€æœº + ä»»åŠ¡è°ƒåº¦å™¨

---

## äºŒã€LangGraph æ ¸å¿ƒæ¦‚å¿µ

### 2.1 å›¾ (Graph)

**å›¾ = èŠ‚ç‚¹ (Nodes) + è¾¹ (Edges)**

```python
from langgraph.graph import StateGraph

# åˆ›å»ºå›¾
graph = StateGraph(AgentState)

# æ·»åŠ èŠ‚ç‚¹
graph.add_node("llm", llm_node)
graph.add_node("tools", tools_node)
graph.add_node("should_continue", should_continue_node)

# æ·»åŠ è¾¹
graph.add_edge("llm", "should_continue")
graph.add_conditional_edges(
    "should_continue",
    route_function,
    {
        "continue": "tools",
        "end": END
    }
)
graph.add_edge("tools", "llm")

# ç¼–è¯‘
app = graph.compile(checkpointer=checkpointer)
```

**å›¾ç»“æ„**ï¼š

```mermaid
graph TD
    START[å¼€å§‹] --> LLM[LLM èŠ‚ç‚¹]
    LLM --> DECIDE{éœ€è¦å·¥å…·ï¼Ÿ}
    DECIDE -->|æ˜¯| TOOLS[å·¥å…·èŠ‚ç‚¹]
    DECIDE -->|å¦| END[ç»“æŸ]
    TOOLS --> LLM
```

### 2.2 çŠ¶æ€ (State)

**çŠ¶æ€æ˜¯å›¾ä¸­æ‰€æœ‰èŠ‚ç‚¹å…±äº«çš„æ•°æ®**ã€‚

```python
from typing import TypedDict, Annotated, Sequence
from langgraph.graph import add_messages

class AgentState(TypedDict):
    """Agent çŠ¶æ€"""
    
    # æ¶ˆæ¯åˆ—è¡¨ï¼ˆè‡ªåŠ¨åˆå¹¶ï¼‰
    messages: Annotated[Sequence[dict], add_messages]
    
    # LLM è°ƒç”¨æ¬¡æ•°
    llm_calls: int
    
    # å·¥å…·è°ƒç”¨æ¬¡æ•°
    tool_calls: int
    
    # æ˜¯å¦éœ€è¦æ¢å¤
    needs_resume: bool
    
    # ç”¨æˆ·ä¿¡æ¯
    user_id: str
    thread_id: str
```

**å…³é”®ç‰¹æ€§**ï¼š

1. **TypedDict**ï¼šç±»å‹å®‰å…¨
2. **Annotated[..., add_messages]**ï¼šè‡ªåŠ¨åˆå¹¶æ¶ˆæ¯
3. **å…±äº«**ï¼šæ‰€æœ‰èŠ‚ç‚¹éƒ½å¯ä»¥è¯»å†™çŠ¶æ€

### 2.3 èŠ‚ç‚¹ (Node)

**èŠ‚ç‚¹æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œè¾“å…¥çŠ¶æ€ï¼Œè¾“å‡ºçŠ¶æ€æ›´æ–°**ã€‚

```python
async def llm_node(state: AgentState) -> dict:
    """LLM èŠ‚ç‚¹"""
    
    # 1. è¯»å–çŠ¶æ€
    messages = state["messages"]
    llm_calls = state.get("llm_calls", 0)
    
    # 2. æ£€æŸ¥è°ƒç”¨æ¬¡æ•°
    if llm_calls >= MAX_LLM_CALLS:
        raise NodeInterrupt(
            code=-1003,
            message="LLM è°ƒç”¨æ¬¡æ•°è¶…é™"
        )
    
    # 3. è°ƒç”¨ LLM
    response = await llm.complete(messages)
    
    # 4. è¿”å›çŠ¶æ€æ›´æ–°
    return {
        "messages": [response],  # ä¼šè¢«è‡ªåŠ¨è¿½åŠ åˆ° messages
        "llm_calls": llm_calls + 1
    }
```

**èŠ‚ç‚¹ç±»å‹**ï¼š

| ç±»å‹ | ä½œç”¨ | ç¤ºä¾‹ |
|------|------|------|
| **Action Node** | æ‰§è¡Œæ“ä½œ | `llm_node`, `tools_node` |
| **Decision Node** | æ¡ä»¶åˆ¤æ–­ | `should_continue_node` |
| **Start Node** | å…¥å£ | è‡ªåŠ¨ç”Ÿæˆ |
| **End Node** | å‡ºå£ | `END` |

### 2.4 è¾¹ (Edge)

**è¾¹å®šä¹‰èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥**ã€‚

**æ™®é€šè¾¹**ï¼š

```python
# A -> B
graph.add_edge("node_a", "node_b")
```

**æ¡ä»¶è¾¹**ï¼š

```python
def route_function(state: AgentState) -> str:
    """è·¯ç”±å‡½æ•°"""
    messages = state["messages"]
    last_message = messages[-1]
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
    if has_tool_call(last_message):
        return "continue"
    else:
        return "end"

# æ ¹æ®æ¡ä»¶é€‰æ‹©ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
graph.add_conditional_edges(
    "should_continue",
    route_function,
    {
        "continue": "tools",
        "end": END
    }
)
```

---

## ä¸‰ã€Checkpoint æœºåˆ¶ï¼ˆæ ¸å¿ƒï¼‰

### 3.1 ä»€ä¹ˆæ˜¯ Checkpointï¼Ÿ

> ğŸ’¡ **æ ¸å¿ƒæ´å¯Ÿ**  
> Checkpoint æ˜¯**å›¾æ‰§è¡Œè¿‡ç¨‹ä¸­çš„çŠ¶æ€å¿«ç…§**ï¼Œç”¨äºä¸­æ–­æ¢å¤ã€‚

**ç±»æ¯”**ï¼š
- **è§†é¢‘æ¸¸æˆçš„å­˜æ¡£ç‚¹**ï¼šéšæ—¶å¯ä»¥ä»å­˜æ¡£ç‚¹æ¢å¤
- **æ•°æ®åº“çš„äº‹åŠ¡æ—¥å¿—**ï¼šå¯ä»¥å›æ»šåˆ°ä»»æ„æ—¶é—´ç‚¹

**Checkpoint åŒ…å«**ï¼š
1. **å½“å‰çŠ¶æ€**ï¼šæ‰€æœ‰ state å­—æ®µçš„å€¼
2. **æ‰§è¡Œä½ç½®**ï¼šå½“å‰åœ¨å“ªä¸ªèŠ‚ç‚¹
3. **å…ƒæ•°æ®**ï¼šthread_id, checkpoint_id, parent_checkpoint_id

### 3.2 Checkpoint çš„å­˜å‚¨

**æ•°æ®ç»“æ„**ï¼š

```python
@dataclass
class Checkpoint:
    """Checkpoint æ•°æ®ç»“æ„"""
    
    # Checkpoint ID
    checkpoint_id: str
    
    # çˆ¶ Checkpoint IDï¼ˆç”¨äºæ„å»ºæ‰§è¡Œé“¾ï¼‰
    parent_checkpoint_id: Optional[str]
    
    # Thread ID
    thread_id: str
    
    # å½“å‰èŠ‚ç‚¹
    current_node: str
    
    # çŠ¶æ€å¿«ç…§
    state: dict
    
    # åˆ›å»ºæ—¶é—´
    created_at: datetime
```

**å­˜å‚¨æ–¹æ¡ˆ**ï¼š

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| **å†…å­˜** | å¿«é€Ÿ | ä¸æŒä¹…åŒ– | å¼€å‘æµ‹è¯• |
| **Redis** | å¿«é€Ÿ + æŒä¹…åŒ– | éœ€è¦å•ç‹¬éƒ¨ç½² | ç”Ÿäº§ç¯å¢ƒï¼ˆçŸ­æœŸï¼‰ |
| **PostgreSQL** | æŒä¹…åŒ– + å¯æŸ¥è¯¢ | ç›¸å¯¹æ…¢ | ç”Ÿäº§ç¯å¢ƒï¼ˆé•¿æœŸï¼‰ |

### 3.3 Checkpoint çš„åºåˆ—åŒ–

**æŒ‘æˆ˜**ï¼šçŠ¶æ€ä¸­å¯èƒ½åŒ…å«ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡

```python
state = {
    "messages": [...],
    "user_id": "user_123",
    "llm_client": <LLMClient object>,  # âŒ ä¸å¯åºåˆ—åŒ–
    "callback": lambda x: x + 1,       # âŒ ä¸å¯åºåˆ—åŒ–
}
```

**è§£å†³æ–¹æ¡ˆ**ï¼šJsonPlusSerializer

ä»ç°æœ‰æ–‡æ¡£å¯ä»¥çœ‹åˆ°ï¼Œç³»ç»Ÿä½¿ç”¨ `JsonPlusSerializer`ï¼š

```python
from langgraph.checkpoint.base import Serializer, SerializerProtocol

class JsonPlusSerializer(Serializer):
    """
    æ”¯æŒæ›´å¤šç±»å‹çš„ JSON åºåˆ—åŒ–å™¨
    """
    
    def dumps(self, obj: Any) -> bytes:
        """åºåˆ—åŒ–å¯¹è±¡"""
        return json.dumps(
            obj,
            default=self._default_handler,
            ensure_ascii=False
        ).encode('utf-8')
    
    def loads(self, data: bytes) -> Any:
        """ååºåˆ—åŒ–å¯¹è±¡"""
        return json.loads(data.decode('utf-8'))
    
    def _default_handler(self, obj: Any) -> Any:
        """å¤„ç†ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡"""
        
        # 1. datetime
        if isinstance(obj, datetime):
            return {
                "__type__": "datetime",
                "value": obj.isoformat()
            }
        
        # 2. UUID
        if isinstance(obj, uuid.UUID):
            return {
                "__type__": "uuid",
                "value": str(obj)
            }
        
        # 3. Pydantic æ¨¡å‹
        if hasattr(obj, 'model_dump'):
            return {
                "__type__": "pydantic",
                "class": obj.__class__.__name__,
                "value": obj.model_dump()
            }
        
        # 4. ä¸æ”¯æŒçš„ç±»å‹ï¼šè·³è¿‡
        return {
            "__type__": "unsupported",
            "class": obj.__class__.__name__
        }
```

### 3.4 è‡ªå®šä¹‰ Checkpointer

```python
from langgraph.checkpoint.base import BaseCheckpointSaver

class RedisCheckpointer(BaseCheckpointSaver):
    """åŸºäº Redis çš„ Checkpointer"""
    
    def __init__(self, redis_client, serializer=None):
        self.redis = redis_client
        self.serializer = serializer or JsonPlusSerializer()
    
    def put(
        self,
        config: dict,
        checkpoint: Checkpoint,
        metadata: dict
    ) -> dict:
        """ä¿å­˜ Checkpoint"""
        
        # 1. ç”Ÿæˆ checkpoint_id
        checkpoint_id = str(uuid.uuid4())
        
        # 2. åºåˆ—åŒ–
        data = self.serializer.dumps({
            "checkpoint": checkpoint,
            "metadata": metadata
        })
        
        # 3. å­˜å‚¨åˆ° Redis
        key = f"checkpoint:{config['thread_id']}:{checkpoint_id}"
        self.redis.set(key, data, ex=3600 * 24 * 7)  # 7å¤©è¿‡æœŸ
        
        # 4. æ›´æ–°æœ€æ–° checkpoint æŒ‡é’ˆ
        latest_key = f"checkpoint:{config['thread_id']}:latest"
        self.redis.set(latest_key, checkpoint_id, ex=3600 * 24 * 7)
        
        return {"checkpoint_id": checkpoint_id}
    
    def get(
        self,
        config: dict,
        checkpoint_id: Optional[str] = None
    ) -> Optional[Checkpoint]:
        """è·å– Checkpoint"""
        
        # 1. å¦‚æœæ²¡æœ‰æŒ‡å®š checkpoint_idï¼Œè·å–æœ€æ–°çš„
        if checkpoint_id is None:
            latest_key = f"checkpoint:{config['thread_id']}:latest"
            checkpoint_id = self.redis.get(latest_key)
            
            if checkpoint_id is None:
                return None
            
            checkpoint_id = checkpoint_id.decode('utf-8')
        
        # 2. è·å– checkpoint æ•°æ®
        key = f"checkpoint:{config['thread_id']}:{checkpoint_id}"
        data = self.redis.get(key)
        
        if data is None:
            return None
        
        # 3. ååºåˆ—åŒ–
        checkpoint_data = self.serializer.loads(data)
        
        return checkpoint_data["checkpoint"]
```

---

## å››ã€ä¸­æ–­ä¸æ¢å¤æœºåˆ¶

### 4.1 ä¸¤ç§ä¸­æ–­æ–¹å¼

#### æ–¹å¼ 1ï¼šNodeInterruptï¼ˆèŠ‚ç‚¹çº§ä¸­æ–­ï¼‰

**åŸç†**ï¼šåœ¨èŠ‚ç‚¹å†…æŠ›å‡º `NodeInterrupt` å¼‚å¸¸

```python
from langgraph.errors import NodeInterrupt

async def tools_node(state: AgentState) -> dict:
    """å·¥å…·èŠ‚ç‚¹"""
    
    messages = state["messages"]
    last_message = messages[-1]
    tool_calls = extract_tool_calls(last_message)
    
    results = []
    for tool_call in tool_calls:
        # æ‰§è¡Œå·¥å…·
        result = await execute_tool(tool_call, state)
        
        # æ£€æŸ¥æ˜¯å¦ç¨¿è±†ä¸è¶³
        if result.get("error") == "insufficient_points":
            # æŠ›å‡ºä¸­æ–­å¼‚å¸¸
            raise NodeInterrupt(
                code=-1002,
                message="ç¨¿è±†ä¸è¶³",
                extra={
                    "last_tool_message_id": tool_call['id']
                }
            )
        
        results.append(result)
    
    return {"messages": results}
```

**LangGraph çš„å¤„ç†**ï¼š

```python
# LangGraph å†…éƒ¨é€»è¾‘ï¼ˆç®€åŒ–ï¼‰
try:
    # æ‰§è¡ŒèŠ‚ç‚¹
    result = await node_function(state)
    
    # æ›´æ–°çŠ¶æ€
    state.update(result)
    
    # ä¿å­˜ Checkpoint
    checkpointer.put(config, state)
    
except NodeInterrupt as e:
    # 1. ä¿å­˜å½“å‰ Checkpointï¼ˆåŒ…å«ä¸­æ–­ä¿¡æ¯ï¼‰
    state["__interrupt__"] = {
        "code": e.code,
        "message": e.message,
        "extra": e.extra
    }
    checkpointer.put(config, state)
    
    # 2. å‘é€çŠ¶æ€æ¶ˆæ¯ç»™å‰ç«¯
    send_status_message(e.code, e.message, e.extra)
    
    # 3. åœæ­¢æ‰§è¡Œ
    return
```

#### æ–¹å¼ 2ï¼šçŠ¶æ€æ ‡è®°ï¼ˆå·¥å…·çº§ä¸­æ–­ï¼‰

**åŸç†**ï¼šåœ¨çŠ¶æ€ä¸­è®¾ç½®æ ‡è®°ï¼Œç”±ä¸‹ä¸€ä¸ªèŠ‚ç‚¹æ£€æµ‹

```python
async def tools_node(state: AgentState) -> dict:
    """å·¥å…·èŠ‚ç‚¹"""
    
    # ... æ‰§è¡Œå·¥å…· ...
    
    if result.get("error") == "insufficient_points":
        # ä¸æŠ›å¼‚å¸¸ï¼Œè€Œæ˜¯è®¾ç½®çŠ¶æ€æ ‡è®°
        return {
            "messages": [{
                "role": "status",
                "content": {
                    "code": -1002,
                    "message": "ç¨¿è±†ä¸è¶³"
                }
            }],
            "needs_resume": True
        }
    
    return {"messages": [result]}


async def should_continue_node(state: AgentState) -> str:
    """åˆ¤æ–­æ˜¯å¦ç»§ç»­"""
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¢å¤
    if state.get("needs_resume"):
        return "interrupt"
    
    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å·¥å…·è°ƒç”¨
    last_message = state["messages"][-1]
    if has_tool_call(last_message):
        return "continue"
    
    return "end"
```

### 4.2 æ¢å¤æ‰§è¡Œ

**å‰ç«¯å‘é€æ¢å¤æ¶ˆæ¯**ï¼š

```python
POST /api/agent/chat
{
  "thread_id": "thread_123",
  "message": null,  # ä¸éœ€è¦æ–°æ¶ˆæ¯
  "resume": true    # æ ‡è®°ä¸ºæ¢å¤è¯·æ±‚
}
```

**åç«¯å¤„ç†æ¢å¤**ï¼š

```python
async def handle_resume(thread_id: str):
    """å¤„ç†æ¢å¤è¯·æ±‚"""
    
    # 1. åŠ è½½æœ€æ–°çš„ Checkpoint
    config = {"thread_id": thread_id}
    checkpoint = checkpointer.get(config)
    
    if checkpoint is None:
        raise ValueError("No checkpoint found")
    
    # 2. æ¢å¤çŠ¶æ€
    state = checkpoint.state
    
    # 3. æ£€æŸ¥ä¸­æ–­ç±»å‹
    if "__interrupt__" in state:
        # èŠ‚ç‚¹çº§ä¸­æ–­ï¼šä»ä¸­æ–­ç‚¹é‡æ–°æ‰§è¡Œ
        interrupt_info = state.pop("__interrupt__")
        
        # æ·»åŠ æ¢å¤æ¶ˆæ¯
        state["messages"].append({
            "role": "status",
            "content": {
                "code": -2001,
                "message": "æ¢å¤æ‰§è¡Œ"
            }
        })
    
    elif state.get("needs_resume"):
        # å·¥å…·çº§ä¸­æ–­ï¼šæ¸…é™¤æ ‡è®°
        state["needs_resume"] = False
        
        # æ·»åŠ æ¢å¤æ¶ˆæ¯
        state["messages"].append({
            "role": "status",
            "content": {
                "code": -2001,
                "message": "æ¢å¤æ‰§è¡Œ"
            }
        })
    
    # 4. ç»§ç»­æ‰§è¡Œå›¾
    result = await app.ainvoke(
        state,
        config=config
    )
    
    return result
```

### 4.3 æ¢å¤æµç¨‹å›¾

```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant Agent
    participant LangGraph
    participant Checkpointer

    User->>Frontend: ç”Ÿæˆå›¾ç‰‡
    Frontend->>Agent: POST /chat
    Agent->>LangGraph: invoke(state)
    LangGraph->>LangGraph: llm_node()
    LangGraph->>LangGraph: tools_node()
    
    Note over LangGraph: æ£€æµ‹åˆ°ç¨¿è±†ä¸è¶³
    
    LangGraph->>Checkpointer: save checkpoint
    LangGraph->>Agent: NodeInterrupt(-1002)
    Agent->>Frontend: SSE: status message
    Frontend->>User: æ˜¾ç¤ºå……å€¼å¼¹çª—
    
    Note over User: ç”¨æˆ·å……å€¼
    
    User->>Frontend: ç‚¹å‡»"ç»§ç»­"
    Frontend->>Agent: POST /chat (resume=true)
    Agent->>Checkpointer: load checkpoint
    Checkpointer-->>Agent: checkpoint (åŒ…å«ä¸­æ–­ç‚¹)
    Agent->>LangGraph: invoke(state, from_checkpoint)
    
    Note over LangGraph: ä»ä¸­æ–­ç‚¹ç»§ç»­
    
    LangGraph->>LangGraph: tools_node()ï¼ˆé‡è¯•ï¼‰
    LangGraph->>Agent: å·¥å…·è°ƒç”¨æˆåŠŸ
    Agent->>Frontend: SSE: function response
    Frontend->>User: æ˜¾ç¤ºç»“æœ
```

---

## äº”ã€å®Œæ•´çš„ Agent å®ç°

### 5.1 å®šä¹‰çŠ¶æ€

```python
from typing import TypedDict, Annotated, Sequence
from langgraph.graph import add_messages

class AgentState(TypedDict):
    """Agent çŠ¶æ€"""
    
    # æ¶ˆæ¯å†å²
    messages: Annotated[Sequence[dict], add_messages]
    
    # è®¡æ•°å™¨
    llm_calls: int
    tool_calls: int
    
    # ä¸Šä¸‹æ–‡ä¿¡æ¯
    user_id: str
    thread_id: str
    input_skill_id: Optional[int]
    
    # ä¸­æ–­æ¢å¤
    needs_resume: bool
```

### 5.2 å®ç°èŠ‚ç‚¹

```python
async def llm_node(state: AgentState) -> dict:
    """LLM èŠ‚ç‚¹"""
    
    # 1. æ£€æŸ¥è°ƒç”¨æ¬¡æ•°
    llm_calls = state.get("llm_calls", 0)
    if llm_calls >= MAX_LLM_CALLS:
        raise NodeInterrupt(
            code=-1003,
            message="LLM è°ƒç”¨æ¬¡æ•°è¶…é™"
        )
    
    # 2. æ„é€  System Prompt
    tools = get_available_tools(state.get("input_skill_id"))
    system_prompt = build_system_prompt(tools)
    
    # 3. è°ƒç”¨ LLM
    messages = state["messages"]
    response = await llm.complete(
        messages=[
            {"role": "system", "content": system_prompt},
            *messages
        ],
        stream=True
    )
    
    # 4. æµå¼è¿”å› + æ”¶é›†å®Œæ•´å“åº”
    full_response = ""
    async for chunk in response:
        full_response += chunk
        yield {
            "type": "chunk",
            "content": chunk
        }
    
    # 5. è¿”å›çŠ¶æ€æ›´æ–°
    return {
        "messages": [{
            "role": "assistant",
            "content": {"type": "plain", "text": full_response}
        }],
        "llm_calls": llm_calls + 1
    }


async def tools_node(state: AgentState) -> dict:
    """å·¥å…·èŠ‚ç‚¹"""
    
    # 1. æå–å·¥å…·è°ƒç”¨
    messages = state["messages"]
    last_message = messages[-1]
    tool_calls = extract_tool_calls(last_message)
    
    if not tool_calls:
        return {}
    
    # 2. æ‰§è¡Œå·¥å…·
    tool_calls_count = state.get("tool_calls", 0)
    results = []
    
    for tool_call in tool_calls:
        # æ£€æŸ¥è°ƒç”¨æ¬¡æ•°
        if tool_calls_count >= MAX_TOOL_CALLS:
            raise NodeInterrupt(
                code=-1003,
                message="å·¥å…·è°ƒç”¨æ¬¡æ•°è¶…é™"
            )
        
        # æ‰§è¡Œå·¥å…·
        result = await execute_tool(
            tool_call,
            context={
                "user_id": state["user_id"],
                "thread_id": state["thread_id"]
            }
        )
        
        # æ£€æŸ¥ç¨¿è±†ä¸è¶³
        if result.get("error") == "insufficient_points":
            raise NodeInterrupt(
                code=-1002,
                message="ç¨¿è±†ä¸è¶³",
                extra={
                    "last_tool_message_id": tool_call.get("id")
                }
            )
        
        results.append({
            "role": "function",
            "content": {
                "type": "function_response",
                "text": result
            },
            "extra": {
                "deduct_points": result.get("deduct_points", 0)
            }
        })
        
        tool_calls_count += 1
    
    # 3. è¿”å›çŠ¶æ€æ›´æ–°
    return {
        "messages": results,
        "tool_calls": tool_calls_count
    }


def should_continue(state: AgentState) -> str:
    """åˆ¤æ–­æ˜¯å¦ç»§ç»­"""
    
    # æ£€æŸ¥æ¢å¤æ ‡è®°
    if state.get("needs_resume"):
        return "interrupt"
    
    # æ£€æŸ¥æœ€åä¸€æ¡æ¶ˆæ¯
    messages = state["messages"]
    if not messages:
        return "end"
    
    last_message = messages[-1]
    
    # å¦‚æœæ˜¯ assistant æ¶ˆæ¯ä¸”åŒ…å«å·¥å…·è°ƒç”¨
    if (last_message["role"] == "assistant" and
        has_tool_call(last_message)):
        return "continue"
    
    # å¦åˆ™ç»“æŸ
    return "end"
```

### 5.3 æ„å»ºå›¾

```python
from langgraph.graph import StateGraph, END

def create_agent_graph(checkpointer):
    """åˆ›å»º Agent å›¾"""
    
    # 1. åˆ›å»ºå›¾
    graph = StateGraph(AgentState)
    
    # 2. æ·»åŠ èŠ‚ç‚¹
    graph.add_node("llm", llm_node)
    graph.add_node("tools", tools_node)
    
    # 3. è®¾ç½®å…¥å£
    graph.set_entry_point("llm")
    
    # 4. æ·»åŠ æ¡ä»¶è¾¹
    graph.add_conditional_edges(
        "llm",
        should_continue,
        {
            "continue": "tools",
            "end": END,
            "interrupt": END
        }
    )
    
    # 5. tools -> llm
    graph.add_edge("tools", "llm")
    
    # 6. ç¼–è¯‘
    app = graph.compile(checkpointer=checkpointer)
    
    return app
```

### 5.4 ä½¿ç”¨ Agent

```python
# åˆå§‹åŒ–
checkpointer = RedisCheckpointer(redis_client)
app = create_agent_graph(checkpointer)

# é¦–æ¬¡è°ƒç”¨
async def chat(user_input: str, thread_id: str, user_id: str):
    """å‘é€æ¶ˆæ¯"""
    
    # 1. æ„é€ åˆå§‹çŠ¶æ€
    state = {
        "messages": [{
            "role": "user",
            "content": {"type": "plain", "text": user_input}
        }],
        "llm_calls": 0,
        "tool_calls": 0,
        "user_id": user_id,
        "thread_id": thread_id,
        "needs_resume": False
    }
    
    # 2. é…ç½®
    config = {
        "thread_id": thread_id,
        "recursion_limit": 20
    }
    
    # 3. æ‰§è¡Œ
    try:
        async for event in app.astream(state, config=config):
            # æµå¼è¿”å›ç»“æœ
            yield event
    
    except NodeInterrupt as e:
        # ä¸­æ–­ï¼šå‘é€çŠ¶æ€æ¶ˆæ¯
        yield {
            "type": "status",
            "content": {
                "code": e.code,
                "message": e.message,
                "extra": e.extra
            }
        }


# æ¢å¤è°ƒç”¨
async def resume(thread_id: str):
    """æ¢å¤æ‰§è¡Œ"""
    
    # 1. åŠ è½½ Checkpoint
    config = {"thread_id": thread_id}
    checkpoint = checkpointer.get(config)
    
    # 2. æ›´æ–°çŠ¶æ€
    state = checkpoint.state
    state["needs_resume"] = False
    state["messages"].append({
        "role": "status",
        "content": {
            "code": -2001,
            "message": "æ¢å¤æ‰§è¡Œ"
        }
    })
    
    # 3. ç»§ç»­æ‰§è¡Œ
    async for event in app.astream(state, config=config):
        yield event
```

---

## å…­ã€æœ€ä½³å®è·µ

### 6.1 çŠ¶æ€è®¾è®¡

**DOï¼š**
- âœ… ä½¿ç”¨ TypedDict å®šä¹‰çŠ¶æ€ç±»å‹
- âœ… ä½¿ç”¨ `add_messages` è‡ªåŠ¨åˆå¹¶æ¶ˆæ¯
- âœ… åªå­˜å‚¨å¯åºåˆ—åŒ–çš„æ•°æ®
- âœ… å°†å¤§å¯¹è±¡ï¼ˆå¦‚ LLM clientï¼‰æ”¾åœ¨å…¨å±€

**DON'Tï¼š**
- âŒ åœ¨çŠ¶æ€ä¸­å­˜å‚¨è¿æ¥å¯¹è±¡
- âŒ åœ¨çŠ¶æ€ä¸­å­˜å‚¨ lambda å‡½æ•°
- âŒ çŠ¶æ€å­—æ®µè¿‡å¤šï¼ˆå½±å“åºåˆ—åŒ–æ€§èƒ½ï¼‰

### 6.2 èŠ‚ç‚¹è®¾è®¡

**DOï¼š**
- âœ… èŠ‚ç‚¹åº”è¯¥æ˜¯çº¯å‡½æ•°ï¼ˆè¾“å…¥çŠ¶æ€ï¼Œè¾“å‡ºçŠ¶æ€æ›´æ–°ï¼‰
- âœ… ä½¿ç”¨ `NodeInterrupt` ä¸­æ–­æ‰§è¡Œ
- âœ… è®°å½•èŠ‚ç‚¹æ‰§è¡Œæ—¥å¿—
- âœ… å¤„ç†å¼‚å¸¸å¹¶è¿”å›é”™è¯¯çŠ¶æ€

**DON'Tï¼š**
- âŒ åœ¨èŠ‚ç‚¹ä¸­ä¿®æ”¹å…¨å±€å˜é‡
- âŒ åœ¨èŠ‚ç‚¹ä¸­ç›´æ¥æ“ä½œæ•°æ®åº“ï¼ˆåº”è¯¥é€šè¿‡å·¥å…·ï¼‰
- âŒ èŠ‚ç‚¹ä¹‹é—´æœ‰éšå¼ä¾èµ–

### 6.3 Checkpoint ç®¡ç†

**DOï¼š**
- âœ… å®šæœŸæ¸…ç†è¿‡æœŸ Checkpoint
- âœ… ä½¿ç”¨åˆé€‚çš„å­˜å‚¨æ–¹æ¡ˆï¼ˆå¼€å‘ç”¨å†…å­˜ï¼Œç”Ÿäº§ç”¨ Redis/PostgreSQLï¼‰
- âœ… ç›‘æ§ Checkpoint å¤§å°
- âœ… è®¾ç½®è¿‡æœŸæ—¶é—´

**DON'Tï¼š**
- âŒ åœ¨ Checkpoint ä¸­å­˜å‚¨æ•æ„Ÿä¿¡æ¯ï¼ˆå¦‚å¯†ç ï¼‰
- âŒ æ— é™åˆ¶ä¿å­˜ Checkpoint
- âŒ åœ¨èŠ‚ç‚¹é—´ä¼ é€’å¤§æ–‡ä»¶

---

## ä¸ƒã€æ€»ç»“

### 7.1 æ ¸å¿ƒæ¦‚å¿µ

1. **LangGraph** æ˜¯æœ‰çŠ¶æ€çš„å·¥ä½œæµç¼–æ’å¼•æ“
2. **Checkpoint** æ˜¯çŠ¶æ€å¿«ç…§ï¼Œç”¨äºä¸­æ–­æ¢å¤
3. **NodeInterrupt** ç”¨äºèŠ‚ç‚¹çº§ä¸­æ–­
4. **çŠ¶æ€æ ‡è®°** ç”¨äºå·¥å…·çº§ä¸­æ–­

### 7.2 å…³é”®å®ç°

- âœ… StateGraphï¼šå®šä¹‰å›¾ç»“æ„
- âœ… Checkpointerï¼šä¿å­˜å’ŒåŠ è½½çŠ¶æ€
- âœ… JsonPlusSerializerï¼šåºåˆ—åŒ–çŠ¶æ€
- âœ… ä¸­æ–­ä¸æ¢å¤ï¼šæ”¯æŒæš‚åœå’Œç»§ç»­

### 7.3 ä¸‹ä¸€æ­¥

- **[ç½‘ç»œæ¶æ„](05-ç½‘ç»œæ¶æ„.md)**ï¼šäº†è§£ç³»ç»Ÿçš„ç½‘ç»œè®¾è®¡
- **[ä¸­æ–­ä¸æ¢å¤](06-ä¸­æ–­ä¸æ¢å¤.md)**ï¼šæ·±å…¥å­¦ä¹ ä¸­æ–­æ¢å¤æœºåˆ¶

---

*æ–‡æ¡£ç‰ˆæœ¬ï¼šv1.0*  
*æœ€åæ›´æ–°ï¼š2026-01-26*

**ä¸Šä¸€ç¯‡**ï¼š[â† å·¥å…·è°ƒç”¨](03-å·¥å…·è°ƒç”¨.md) | **ä¸‹ä¸€ç¯‡**ï¼š[ç½‘ç»œæ¶æ„ â†’](05-ç½‘ç»œæ¶æ„.md)
